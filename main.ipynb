{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constantes das pastas de treino e validação\n",
    "train_dir = 'train_data/'\n",
    "val_dir = 'val_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.2, rotation_range=120, horizontal_flip=True, validation_split=0.2, rescale = 1./255,)\n",
    "val_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,)\n",
    "\n",
    "train_dataset = train_data_gen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='categorical', subset='training')\n",
    "val_dataset = train_data_gen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='categorical', subset='validation')\n",
    "\n",
    "\n",
    "test_dataset = val_data_gen.flow_from_directory(val_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                1968192   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1969413 (7.51 MB)\n",
      "Trainable params: 1969413 (7.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(64, 64, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters= 128, kernel_size=(5, 5), activation='relu', strides=(1,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters= 64, kernel_size=(3, 3), activation='relu', strides=(1,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters= 32, kernel_size=(2, 2), activation='relu', strides=(1,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(units = 5, activation='softmax', name = 'saida'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'max', patience = 10)\n",
    "\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=100, callbacks = [early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o ERRO de treinamento\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'], ':')\n",
    "plt.title('Função perda')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend(['Erro de Treinamento', 'Erro de Validação'])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o treinamento e a validação da accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'], '--')\n",
    "plt.yscale(\"log\")\n",
    "plt.title('Acurácia')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões do modelo no conjunto de validação\n",
    "val_predictions = model.predict(val_dataset)\n",
    "val_pred_classes = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Rótulos verdadeiros do conjunto de validação\n",
    "val_true_classes = val_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(val_true_classes, val_pred_classes)\n",
    "print(\"Acurácia (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular precisão\n",
    "precision = precision_score(val_true_classes, val_pred_classes, average='macro')\n",
    "print(\"Precisão (Precision):\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular recall\n",
    "recall = recall_score(val_true_classes, val_pred_classes, average='macro')\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular F1 score\n",
    "#f1 = f1_score(val_true_classes, val_pred_classes, average='macro')\n",
    "#print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e exibir a matriz de confusão\n",
    "cm = confusion_matrix(val_true_classes, val_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = train_dataset.class_indices\n",
    "print(class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o modelo\n",
    "teste_image_path = 'moeda.jpg'  # Substitua pelo caminho da sua imagem de teste\n",
    "teste_image = tf.keras.preprocessing.image.load_img(teste_image_path, target_size=(64, 64))\n",
    "teste_image_array = tf.keras.preprocessing.image.img_to_array(teste_image)\n",
    "teste_image_array = np.expand_dims(teste_image_array, axis=0)  # Adiciona uma dimensão para representar o lote (batch)\n",
    "\n",
    "# Normaliza a imagem\n",
    "#teste_image_array /= 255.0\n",
    "\n",
    "# Predição\n",
    "saida_predita = model.predict(teste_image_array)\n",
    "\n",
    "print('Saída Preditada:', saida_predita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento de números de classe para nomes de classe\n",
    "class_name = {\n",
    "    0: \"Moeda de 5 centavos\",\n",
    "    1: \"Moeda de 10 centavos\",\n",
    "    2: \"Moeda de 25 centavos\",\n",
    "    3: \"Moeda de 50 centavos\",\n",
    "    4: \"Moeda de 1 real\"\n",
    "}\n",
    "\n",
    "# Obtém o número da classe prevista\n",
    "classe_prevista = np.argmax(saida_predita)\n",
    "\n",
    "# Obtém o nome da classe prevista usando o mapeamento\n",
    "nome_classe_prevista = class_name[classe_prevista]\n",
    "\n",
    "print('Classe Prevista:', nome_classe_prevista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar previsões no conjunto de validação\n",
    "saida_predida_test = model.predict(test_dataset)\n",
    "\n",
    "# Exibir as primeiras 5 previsões\n",
    "print(saida_predida_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mode_acurracy82.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.DataFrame(history.history)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.to_csv('loss.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
